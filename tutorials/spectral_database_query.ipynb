{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLAT Tutorials: Database Query Tools\n",
    "\n",
    "## Authors\n",
    "Adam Burgasser\n",
    "\n",
    "## Version date\n",
    "27 May 2023\n",
    "\n",
    "## Learning Goals\n",
    "* Explore some of the data spreadsheet manipulation tools built into SPLAT (``splat.database.prepDB``)\n",
    "* Learn how to use the astroquery wrapper for Vizier to get individual source information (``splat.database.getPhotometry``, ``splat.database.querySimbad``)\n",
    "* Learn how to use the astroquery wrapper for Simbad to get individual source information (``splat.database.querySimbad``)\n",
    "* Learn how to use the astroquery wrapper for XMatch to get information for many sources (``splat.database.queryXMatch``)\n",
    "\n",
    "## Keywords\n",
    "astroquery, databases\n",
    "\n",
    "## Companion Content\n",
    "None\n",
    "\n",
    "## Summary\n",
    "In this tutorial, we are going to see how to use the splat.database functions to manage source spreadsheets and query online databases for source informaiton.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main splat import\n",
    "import splat\n",
    "import splat.database as spdb\n",
    "\n",
    "# other useful imports\n",
    "import astropy.units as u\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure this is at least 2023.05\n",
    "splat.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping datasets\n",
    "\n",
    "SPLAT useds pandas as its default spreadsheet format. There is a simple tool called prepDB available to manage sets of data to assure one has sufficient informaiton to query online catalogs. We're going to explore a couple of cases based on the targets observed by Terrien et al. (2015), for which there are two .csv files in the SPLAT tutorial directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with a folder of RA & DEC\n",
    "db = pandas.read_csv(splat.SPLAT_PATH+splat.TUTORIAL_FOLDER+'terrien2015_radec.csv')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the necessary information for queries with prepDB\n",
    "# this adds in columns for designation and SkyCoord coordinates\n",
    "db = spdb.prepDB(db)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternately let's assume we have a file that contains only designations\n",
    "db = pandas.read_csv(splat.SPLAT_PATH+splat.TUTORIAL_FOLDER+'terrien2015_designations.csv')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepDB will adds in the columns for RA, Dec and SkyCoord coordinates\n",
    "db = spdb.prepDB(db)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting photometry with getPhotometry\n",
    "\n",
    "The ``splat.database.getPhotometry()`` is a wrapper for astroquery.Vizier, allowing you to query the Vizier network of catalogs to find relevant photometry and other information. This code is particularly well suited for searching on source at a time; for a large number of sources it is probably better to use ``splat.database.queryXMatch()``. To start, let's find 2MASS, SDSS and WISE data for one of the sources in our catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the docstring for this function\n",
    "spdb.getPhotometry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look to see what input catalogs are available\n",
    "# the links point to the information page on this catalog in Vizier\n",
    "spdb.getPhotometry(_,info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first coordinate and search for 2MASS photometry\n",
    "# this will search within 30\" of the target and \n",
    "# return a pandas spreadsheet in order of separation from the original coordinate\n",
    "srch = spdb.getPhotometry(db['COORDINATES'].iloc[0],catalog='2MASS',radius=30*u.arcsec)\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to return only the nearest target, set nearest=True\n",
    "srch = spdb.getPhotometry(db['COORDINATES'].iloc[0],catalog='2MASS',radius=30*u.arcsec,nearest=True)\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the duplicate function spdb.queryVizier does the same thing\n",
    "srch = spdb.queryVizier(db['COORDINATES'].iloc[0],catalog='2MASS',radius=30*u.arcsec,nearest=True)\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add the 2MASS J, H, and K magnitudes and their uncertainties \n",
    "# to our original spreadsheet\n",
    "# first set up columns\n",
    "cstring = ['Jmag','e_Jmag','Hmag','e_Hmag','Kmag','e_Kmag','sep']\n",
    "for c in cstring: \n",
    "    db[c] = np.zeros(len(db))\n",
    "\n",
    "# now add our measurement for the nearest source\n",
    "for c in cstring: \n",
    "    db[c].iloc[0] = srch[c].iloc[0]\n",
    "\n",
    "db.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's repeat for the first 30 positions - this will take several seconds!\n",
    "for i,crd in enumerate(db['COORDINATES'].iloc[:30]):\n",
    "    srch = spdb.getPhotometry(crd,catalog='2MASS',radius=30.*u.arcsec,nearest=True)\n",
    "# catch for case where nothing is returned\n",
    "    if len(srch)>0: \n",
    "        for c in cstring: \n",
    "            db[c].iloc[i] = srch[c].iloc[0]\n",
    "db.iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can search on other catalogs in Vizier as well by entering in the catalog reference\n",
    "# here's an example for TESS Input Catalog (TIC) of Stassun et al. 2019\n",
    "# see https://cdsarc.unistra.fr/viz-bin/cat/IV/38\n",
    "cat = 'IV/38/tic'\n",
    "srch = spdb.getPhotometry(db['COORDINATES'].iloc[0],catalog=cat,radius=30*u.arcsec,nearest=True)\n",
    "srch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Explore some of the other catalogs that are available in the getPhotometry code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying SIMBAD\n",
    "\n",
    "The ``splat.database.querySimbad()`` function searches specifically on the Simbad database, and looks a lot like ``splat.database.getPhotometry()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for SIMBAD sources around the first coordinate in our table\n",
    "srch = spdb.querySimbad(db['COORDINATES'].iloc[0],radius=5*u.arcminute)\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what information we get from this\n",
    "srch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all of these sources are what we want, so we can reject by object type\n",
    "srch = spdb.querySimbad(db['COORDINATES'].iloc[0],radius=5*u.arcminute,reject_type='Galaxy')\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also return the nearest soruce to our coordinate\n",
    "srch = spdb.querySimbad(db['COORDINATES'].iloc[0],radius=5*u.arcminute,nearest=True)\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also search by the name of the source\n",
    "srch = spdb.querySimbad('G 158-27',isname=True)\n",
    "srch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is also a slightly reformated version of the output that can be returned\n",
    "srch = spdb.querySimbad(db['COORDINATES'].iloc[0],radius=5*u.arcminute,clean=True)\n",
    "srch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query a large collection of sources: queryXMatch\n",
    "\n",
    "Each of these methods is fine for individual sources, but can be slow for a large list of objects (like our sample database!). Fortunately, the astroquery xmatch function is well suited to this case, and SPLAT as a wrapper for this called ``splat.database.queryXMatch()``. In this case, you input the entire table, and as long as DESIGNATION or RA and DEC columns are provided, it will return the closest match to each source in the catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's reload our catalog\n",
    "db = pandas.read_csv(splat.SPLAT_PATH+splat.TUTORIAL_FOLDER+'terrien2015_radec.csv')\n",
    "db = spdb.prepDB(db)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get all the 2MASS data for this catalog - it's pretty fast!\n",
    "db2 = spdb.queryXMatch(db,radius=30.*u.arcsec,catalog='2MASS')\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we want only a few select columns; we can use the pre-select versions\n",
    "db2 = spdb.queryXMatch(db,radius=30.*u.arcsec,catalog='2MASS',use_select_columns=True)\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also specific the columns we want to keep\n",
    "# as long as they are among the columns returned by the catalog\n",
    "# note that we've dropped the 2MASS prefix\n",
    "# one of these columns won't work and will throw up a warning\n",
    "select_columns = ['Jmag','e_Jmag','Hmag','e_Hmag','Kmag','e_Kmag','JUNK']\n",
    "db2 = spdb.queryXMatch(db,radius=30.*u.arcsec,catalog='2MASS',select_columns=select_columns,use_select_columns=False)\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also query Simbad\n",
    "db2 = spdb.queryXMatch(db,radius=30.*u.arcsec,catalog='SIMBAD')\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also query other Vizier catalogs\n",
    "# let's again look at the  TESS Input Catalog (TIC) of Stassun et al. 2019\n",
    "# I've changed the name of the catalog prefix to make my columns cleaner\n",
    "cat = 'IV/38/tic'\n",
    "db2 = spdb.queryXMatch(db,radius=30.*u.arcsec,catalog=cat,prefix='TIC')\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the great thing about queryXMatch is that searches to multiple catalogs \n",
    "# can be strung together to produce an overall dataset\n",
    "db2 = copy.deepcopy(db)\n",
    "for cat in ['SDSS','2MASS','ALLWISE','GAIA-EDR3']:\n",
    "    db2 = spdb.queryXMatch(db2,catalog=cat,radius=30*u.arcsec)\n",
    "db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of columns!\n",
    "print(list(db2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can generate some absolute magnitudes and colors\n",
    "magnitudes =  ['SDSS_gmag','SDSS_rmag','SDSS_imag','SDSS_zmag','GAIA-EDR3_phot_g_mean_mag','GAIA-EDR3_phot_bp_mean_mag','GAIA-EDR3_phot_rp_mean_mag','2MASS_Jmag','2MASS_Hmag','2MASS_Kmag','ALLWISE_W1mag','ALLWISE_W2mag','ALLWISE_W3mag','ALLWISE_W4mag']\n",
    "for i,m in enumerate(magnitudes):\n",
    "    db2['ABSOLUTE_{}'.format(m)] = db2[m]-5.*np.log10(db2['GAIA-EDR3_parallax']/100)\n",
    "    for m2 in magnitudes[(i+1):]:\n",
    "        db2['{}-{}'.format(m,m2)] = db2[m]-db2[m2]\n",
    "print(list(db2.columns[-100:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some color-color and color-magnitude plots\n",
    "combinations = [\n",
    "    ['ABSOLUTE_GAIA-EDR3_phot_g_mean_mag','GAIA-EDR3_phot_bp_mean_mag-GAIA-EDR3_phot_rp_mean_mag'],\n",
    "    ['ABSOLUTE_SDSS_imag','SDSS_imag-SDSS_zmag'],\n",
    "    ['ABSOLUTE_2MASS_Jmag','2MASS_Jmag-2MASS_Kmag'],\n",
    "    ['ABSOLUTE_ALLWISE_W2mag','2MASS_Jmag-ALLWISE_W2mag'],\n",
    "    ['2MASS_Jmag-2MASS_Kmag','SDSS_imag-SDSS_zmag'],\n",
    "    ['2MASS_Jmag-ALLWISE_W2mag','SDSS_rmag-2MASS_Kmag'],\n",
    "]\n",
    "fig, axs = plt.subplots(6,figsize=[5,15])\n",
    "for i,c in enumerate(combinations):\n",
    "    axs[i].plot(db2[c[1]],db2[c[0]],'o',alpha=0.5)\n",
    "    axs[i].set_xlabel(c[1])\n",
    "    axs[i].set_ylabel(c[0])\n",
    "    axs[i].set_xlim(np.nanquantile(db2[c[1]],[0.05,0.95]))\n",
    "    axs[i].set_ylim(np.nanquantile(db2[c[0]],[0.95,0.05]))\n",
    "fig.tight_layout()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
